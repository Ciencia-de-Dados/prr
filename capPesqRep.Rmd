---
title: "Pesquisa Reproduzível"
author: "Fernando Mayer & Walmes Zeviani"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
source("setup_knitr.R")
```

# Introdução

Atualmente a evolução da tecnologia, mais especificamente em como
coletamos, processamos e analisamos dados, têm possibilitado a
interpretação de bases de dados complexas e de alta dimensão. Algumas
bases de dados podem ser geradas quase que instantaneamente, se
comparado à alguns anos atrás. Além disso, utilizamos o alto poder
computacional atual para combinar bases de dados existentes (que já
possuem grandes dimensões) em bases de dados cada vez maiores. Também
utilizamos a alta capacidade de processamento para implementar rotinas
de análise cada vez mais sofisticadas e complexas.

Mas quem garante que toda essa informação, e todo esse resultado que vem
sendo gerado pode ser confiável? Não existe uma resposta direta para
essa pergunta, e certamente a confiabilidade de uma informação depende
de muitos fatores. Uma possibilidade é confiarmos na afirmação que
alguém fez, e simplesmente acreditar que isso seja verdade. Você tomaria
um comprimido que alguém está distribuindo na rua afirmando que ele cura
a sua dor de cabeça? E se um médico lhe oferecesse esse mesmo
comprimido, isso faria você tomar o remédio com mais segurança?
Certamente sim, mas quem garante que o médico não possa estar errado e o
remédio causar um efeito colateral devastador em você? A resposta para
essa pergunta é fácil. Considerando que o médico seja responsável, ele
**pesquisou** antes de indicar a medicação para alguém. Mas quem garante
que a pesquisa que o médico se baseou é confiável? É aí que entra a
teoria da ciência e as formas de validação de um
resultado. (*Arrumar essa ideia e continuar...*)

As análises, os modelos e os algoritmos que usamos hoje em dia são
muito mais complexos do que no passado. Ter um entendimento básico
de tudo isso é difícil, até mesmo para os mais qualificados, e é quase
impossível descrever todos os detalhes em palavras apenas. Por isso,
entender o que alguém fez em uma análise de dados atualmente, requer
olhar para o *código*, e examinar minuciosamente as rotinas utilizadas
pelas pessoas.

<div class="panel panel-primary">
  <div class="panel-heading">Um estudo de caso</div>
  <div class="panel-body">

  Em 2006, um artigo no *New England Journal of Medicine*, dos Drs. Anil
  Potti, Joseph Nevins e colaboradores da Universidade de Duke, chamou a
  atenção da comunidade médica em geral. Os autores relataram que
  poderiam prever a evolução do câncer de pulmão de um paciente usando
  dispositivos chamados de matrizes de expressão, que rastreiam os
  padrões de atividade de milhares de genes em uma amostra de tecido
  como uma imagem colorida. Alguns meses mais tarde, eles publicaram na
  *Nature Medicine* que eles tinham desenvolvido uma técnica semelhante,
  que utilizou a expressão de genes em culturas de laboratório de
  células cancerosas, conhecidas como linhas de células, para prever a
  quimioterapia mais eficaz para pacientes que sofrem de câncer de
  pulmão, mama ou de ovário.

  Aparentemente, os resultados publicados pareciam um enorme avanço no
  tratamento do câncer. De fato, algumas semanas depois da publicação
  na *Nature Medicine*, um grupo de bioestatísticos do MD Anderson
  Cancer Centre tentava reproduzir os resultados do artigo, com a
  finalidade de usar a nova técnica. Ao encontrar algumas dificuldades,
  os pesquisadores entraram em contato com Dr. Potti, solcitando os
  dados brutos e os códigos da análise conduzida em Duke.

  Os pesquisadores de Duke forneceram o material, e logo começaram a
  surgir diversos questionamentos sobre a metodologia utilizada
  originalmente. Os pesquisadores que tantavam reproduzir a análise
  encontraram diversas falhas como linhas de células com nomes errados,
  nomes e números de células inconsistentes, etc.

  Os questionamentos foram publicamente respondidos, e além disso, o
  grupo de Duke iniciou três ensaios clínicos baseados nos trabalhos
  publicados. Também havia a intenção de utilizar a metodologia em um
  ensaio clínico financiado pela *America's National Cancer Institute*
  (NCI), o que levou Lisa McShane, uma bioestatística da NCI, também
  tentar reproduzir o trabalho, o que também foi em vão.

  Depois disso, uma série de investigações foram realizadas, inclusive
  por outros pesquisadoresda Duke, levando a cessar os ensaios clínicos
  já iniciados pela Universidade. Dr. Potti pediu demissão, e depois foi
  descoberto que ele tinha envolvimento com empresas da área biomédica.

  Como lição: o processo de revisão por pares de revistas científicas
  depende da disponibilidade de pesquisadores, que frequentemente não
  tem a disponibilidade para revisar uma publicação da maneira como
  deveria. Além do mais, a seção "métodos" de um artigo deveria conter
  toda a informação necessária para que a análise seja reproduzida, o
  que frequentemente não acontece.
  </div>
</div>

# Como a ciência funciona

A ciência é ...

Para que um resultado de uma pesquisa científica possa ser considerado
como válido, é necessário que este resultado possa ser **replicado** por
diversos cientistas. A replicação é um dos pilares fundamentais da
ciência. Basicamente é necessário que diversos cientistas coletem e
analisem dados de forma independente, e cheguem no mesmo
resultado. Dessa forma se você chegar à conclusão de que X causa Y, ou
que a vitamina C melhora a doença Z, ou que alguma coisa causa algum
problema, será necessário que outros cientistas, independentes de você,
cheguem no mesmo resultado. Se muitas pessoas diferentes chegarem à
mesma conclusão de forma independente, então tendemos a pensar que a
relação ou resultado provavelmente é verdadeiro.

A replicação na ciência têm sido praticada há muitos anos. No entanto,
hojem em dia esta prática tem se tornado cada vez mais desafiadora, uma
vez que os estudos estão se tornando cada vez maiores e mais caros, e a
disponibilidade de recursos financeiros para pesquisas cada vez mais
escassa. Além disso, existem estudos que dificilmente podem ser
replicados, como por exemplo, a avaliação do impacto de um terremoto em
um determinado local, a evolução do crescimento de uma floresta, ou um
estudo clínico que acompanhou as reações de pacientes à um medicamento
durante 20 anos.

Existem muitas boas razões pelas quais não podemos replicar um
estudo. Se replicar não é possível, então a opção seria não fazer nada,
e ter como informação apenas o resultado de um estudo. No entanto, não
fazer nada não é (e não pode ser) uma opção para cientistas. É nesse
ponto que entra o conceito de **pesquisa reproduzível**. A ideia é criar
uma espécie de "padrão mínimo", ou um "meio-termo" entre replicar um
estudo e não fazer nada, fazer algo no meio. O problema básico é que
temos o padrão ideal, que é a replicação, e o padrão nulo, que é não
fazer nada. O que pode ser feito entre o melhor (que não é possível) e o
pior (que não é desejável), é a reprodução dos resultados. É uma forma
de preencher a lacuna de informação entre replicação e nada.

```
Figura com esquema de replicação e reprodução

##------------------------------------------------------------------------
## Replicação

+------------------+
|                  |                         +------------------+
|      Estudo      |                         |                  |
|        1         | +-------------------->  |   Resultado X    |
|      Dados       |                         |                  |
|                  |                         +------------------+
+------------------+
+------------------+
|                  |                         +------------------+
|      Estudo      |                         |                  |
|        2         | +-------------------->  |   Resultado X    |
|      Dados       |                         |                  |
|                  |                         +------------------+
+------------------+
+------------------+
|                  |                         +------------------+
|      Estudo      |                         |                  |
|        3         | +-------------------->  |   Resultado X    |
|      Dados       |                         |                  |
|                  |                         +------------------+
+------------------+

##------------------------------------------------------------------------
## Reprodução

                             +---------------+
                             |  Resultado X  |
                     +-----> |               |
                     |       +---------------+
                     |
+------------------+ |
|                  | |                      +-------------------+
|      Estudo      | |                      |                   |
|        1         | +--------------------> |    Resultado X    |
|      Dados       | |                      |                   |
|                  | |                      +-------------------+
+------------------+ |
                     |
                     |        +--------------+
                     +------> |  Resultado X |
                              |              |
                              +--------------+
```

Uma pesquisa reproduzível é aquela que pode ser reproduzida por outras
pessoas de maneira independente, com o objetivo de que todas cheguem ao
mesmo resultado. Por isso, uma parte fundamental da pesquisa
reproduzível é tornar disponíveis os **dados** do estudo original, e os
**métodos computacionais** (em forma de código) utilizados para se
chegar no resultado. Dessa forma, qualquer pessoa poderá olhar para os
dados, realizar a análise proposta, e chegar exatamente nos mesmos
resultados.

Nesse ponto, a pergunta é: se reproduzir uma análise leva à um resultado
já conhecido e esperado, então qual seria o propósito de se fazer (ou de
tornar) uma pesquisa reproduzível? Como mencionado anteriormente, a
pesquisa reproduzível não é uma forma de replicação, mas é melhor do que
não se fazer nada. O propósito principal de reproduzir uma pesquisa é o
de **validação da análise de dados**. Como não há coleta de dados e
métodos analíticos independentes, realmente é difícil validar a questão
científica propriamente dita. Mas, se conseguimos reproduzir uma análise
e chegar no mesmo resultado do autor original, então de alguma forma
estamos validando aquela análise de dados. Com isso, no mínimo podemos
ter confiança de que aquela análise foi realizada apropriadamente e que
os métodos corretos foram utilizados.

Além disso, a possibilidade de reproduzir um estudo com os dados
originais também permite que diferentes cientistas, com diferentes
visões e ideias possam colaborar no sentido de continuar a pesquisa, ou
sugerir outras abordagens de análise, ou abrindo novas possibilidades
para novas perguntas. Dessa forma, a pesquisa reproduzível deve ser
vista como um processo dinâmico, e não estático, onde o fim seria chegar
no resultado esperado. O verdadeiro trunfo da pesquisa reproduzível é
quando novas ideias e perguntas surgem a partir dos resultados
encontrados, e a disponibilização de dados e códigos podem fazer com que
o processo de geração de conhecimento (que é um dos objetivos da
ciência) seja mais rápido e dinâmico. No futuro, podem existir outras
abordagens e formas de pensar no mesmo problema, e nesse sentido, novos
métodos podem ser utilizados para analisar os dados disponibilizados. Se
o resultado encontrado for sempre o mesmo, também tendemos a acreditar
que deve ser verdadeiro.

E a questão sobre propriedade intelectual, plágio, etc?

Nos últimos anos têm havido muita discussão sobre pesquisa reproduzível
na literatura científica e na mídia. Muitas revistas científicas tem
atualizado suas políticas de publicação, para encorajar a
reproducibilidade dos artigos publicados. Em 2012, foi discutido em um
programa de TV um incidente com uma pesquisa promissora para um teste de
câncer na universidade de Duke. Chegou-se à conclusão que os resultados
da pesquisa não podiam ser reproduzidos, levando até a paralisação do
estudo. (*Aqui precisa citar fontes e talvez dar mais detalhes. Procurar
casos mais concretos*.)

# Boas práticas para a computação científica

Para promover, encorajar, e padronizar a reproducibilidade de
investigações científicas, algumas práticas podem ser adotadas. De
maneira geral, as peças chave de pesquisa reproduzível são:

- Disponibilização de dados e metadados
- Disponibilização do código computacional que gerou a análise, que deve
  ser completamente especificado
- Todos os passos da análise devem ser descritas, incluindo o
  pré-processamento de dados quando houver, para que as pessoas possam
  estudá-la e reproduzi-la

De maneira mais específica, podemos listar oito práticas consideradas
essenciais para que a reproducibilidade seja eficiente:

1. Escreva programas para humanos, não para computadores
2. Deixe o computador fazer o trabalho
3. Faça alterações incrementais
4. Não repita você mesmo (ou outros)
5. Prepare para erros
6. Otimize código apenas depois que ele funcionar
7. Documente a ideia e o propósito, não a mecânica do programa
8. Colabore

(*Expandir essa parte baseada em Wilson et al, 2014*).


# Elementos da reproducibilidade

1. Dados
2. Código
3. Documentação
4. Distribuição


# Análise de dados como arte

Em 1974, Donald Knuth descreveu a diferença entre arte e ciência da
seguinte forma:

> Ciência é conhecimento que entendemos tão bem que podemos ensiná-la
> para um computador. Todo o resto é arte.

Imagine um compositor escrevendo a letra de uma música. Certamente
existem regras gerais de como uma boa música deve ser estruturada: qual a
duração, número de versos, etc. Em outras palavras, existe um estrutura
geral (mesmo que abstrata) para músicas em geral. No entanto, o
conhecimento dessa estrutura e de teoria musical sozinhas não fazem uma
boa música. É necessário algo mais. Em algum momento, o compositor deve
injetar algo mais, alguma coisa que faça com que sua música seja
diferente das outras e que as pessoas queiram ouvir. Esta parte criativa
é difícil de explicar, mas é essencial para o processo de composição. Se
não fosse assim, bastaria programarmos um computador para compor
músicas, o que (para o bem ou para o mal) ainda não aconteceu.

Assim como a composição de uma música, o processo de analisar dados
também é uma arte. Não é uma coisa que podemos ensinar para um
computador. Análise de dados também possui uma estrutura geral e teorias
envolvidas como regressão linear, árvores de classificação, etc., e
todas estas teorias já foram ensinadas para os computadores. No entanto,
cabe ao analista de dados saber como juntar todas estas ferramentas e
aplicá-las para responder questões relevantes para a ciência e para as
pessoas. (Peng e Matsui, 2015).

# Pesquisa reproduzível

> *The source code is real*
>
> > ESS Project

Pseudo-código para escrever um artigo ou relatório científico:

```{r, results="asis", eval=FALSE}
1. Importe uma base de dados para um *software*
2. Execute um procedimento analítico
3. Gere tabelas e figuras separadamente
4. Copie os resultados de análises
5. Coloque tudo isso em um editor de texto e escreva o documento
```

Mudou alguma linha na base de dados? Esqueceu de algo? Volte para o item
(1) e repita o processo (e boa sorte)!

Pseudo-código para escrever um artigo ou relatório científico
**reprodutível**:

```{r, results="asis", eval=FALSE}
1. Use o R Markdown e realize os 5 passos acima em um único documento
```

Mudou alguma linha na base de dados? Esqueceu de algo? Altere o código e
gere um novo documento.

* Dessa forma, um documento pode ser gerado dinamicamente a partir de um
  **código-fonte**.
* Da mesma forma que um *software* possui seu código-fonte, um documento
  dinâmico é o código-fonte de um relatório.
* É uma combinação de código de computador e as correspondentes
  narrativas descrevendo o resultado que o código está gerando (números,
  tabelas, figuras, ...).
* Quando **compilamos** o documento dinâmico, o código de computador é
  executado, e as saídas são apresentadas. Portanto obtemos um documento
  final que mistura **código** e **texto**.
* Como gerenciamos apenas o código-fonte do documento, ficamos livres de
  todas as etapas manuais mencionadas acima.

# Literate Programming

> *Instead of imagining that our main task is to instruct a computer what
> to do, let us concentrate rather on explaining to humans what we want
> the computer to do.*
>
> > Donald Knuth

O ideia básica por trás de documentos dinâmicos decorre diretamente do
conceito de *literate programming* ("programação letrada"), um paradigma
concebido por [Donald Knuth][] em 1984.

<table>
<tr>
<td align="center"><img src="img/knuth.jpg" height="50%"></td>
<td align="center"><img src="img/Literate_Programming_book_cover.jpg" height="55%"></td>
</tr>
</table>

* O conceito é o de misturar **literatura** (o texto em uma
  linguagem humana) com **códigos de programação**, tornando claro cada
  etapa de um programa e/ou análise
* Com um único código-fonte, podemos
	- Produzir documentos para humanos (HTML, PDF, ...) &rArr; *weave*
	- Produzir documentos para máquinas (código) &rArr; *tangle*
* Knuth criou um sistema chamado **WEB** para fazer essa mistura
  dos seus textos em $TeX$ com a linguagem Pascal
* Atualmente muitos outros sistemas existem para misturar códigos
  com texto em várias linguagens

## Literate Programming no R

Com a ascensão do R no início dos anos 2000, [Friedrich Leisch] criou
o [Sweave] em 2002

* S + weave
* Permite "entrelaçar" textos do $LaTeX$ com códigos do R
* Ainda é muito utilizado e já é distribuído como uma função do R
  dentro do pacote `utils`

No final de 2011, [Yihui Xie][] criou o pacote [knitr][] com
a proposta de ser mais flexível, fácil e **preparado para a Web**

> *knitr = Sweave + cacheSweave + pgfSweave + weaver +
>     animation::saveLatex + R2HTML::RweaveHTML +
>    highlight::HighlightWeaveLatex + 0.2 * brew + 0.1 *
>    SweaveListingUtils + more*

* knit + R
* Uma re-implementação mais moderna do Sweave
* Permite "entrelaçar" textos do $LaTeX$, HTML e **Markdown** com
  códigos do R
* Também permite misturar texto com códigos de outras linguagens:
  Python, awk, C++, shell.
* Adiciona muitas facilidades como
	- Cache
	- Decoração e formatação automática de códigos
	- Geração de gráficos mais direta


<!-- links -->

[Donald Knuth]: https://en.wikipedia.org/wiki/Donald_Knuth
[MathJax]: http://www.mathjax.org
[Dingus]: http://daringfireball.net/projects/markdown/dingus
[Markdown]: http://daringfireball.net/projects/markdown
[rmarkdown]: http://rmarkdown.rstudio.com
[Friedrich Leisch]: http://www.statistik.lmu.de/~leisch
[Sweave]: https://www.statistik.lmu.de/~leisch/Sweave
[Yihui Xie]: http://yihui.name/
[knitr]: http://yihui.name/knitr
[Pandoc]: http://pandoc.org/
[YAML]: http://yaml.org/
[linguagem de marcação]: https://pt.wikipedia.org/wiki/Linguagem_de_marcação/
